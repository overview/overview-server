# DocumentCloud URL. Must be HTTPS.
#
# Used for fetching documents into the database. If you're running your own
# DocumentCloud installation, set DOCUMENTCLOUD_URL
documentcloud_url: "https://www.documentcloud.org"
documentcloud_url: ${?DOCUMENTCLOUD_URL}
documentcloud_id_list_page_size=500

db {
  default {
    dataSourceClassName=org.postgresql.ds.PGSimpleDataSource
    maximumPoolSize=4
    leakDetectionThreshold=20000
    dataSource {
      serverName="localhost"
      portNumber="5432"
      databaseName="overview"
      user="overview"
      password="overview"
      serverName=${?DATABASE_SERVER_NAME}
      portNumber=${?DATABASE_PORT}
      databaseName=${?DATABASE_NAME}
      user=${?DATABASE_USERNAME}
      password=${?DATABASE_PASSWORD}

      tcpKeepAlive=true
      ssl=${?DATABASE_SSL} # "true" or unset
      sslfactory=${?DATABASE_SSL_FACTORY}
    }
  }
}

# Search index configuration (defaults are hard-coded)
search_index {
  hosts:"127.0.0.1:9200"
  hosts:${?ES_HOSTS}
}

# How Overview stores blobs.
#
# (What's a "blob"? It's a bunch of data that we always treat as a unit: for
# instance, a PDF or a user-uploaded file. Blobs may be >1GB.)
#
# We store blobs at "locations", which are quasi-URLs. For instance, "pglo:123"
# stores a blob as a Postgres Large Object with loid "123". "s3:foo:bar" stores
# an S3 object "bar" in bucket "foo".
#
# The default configuration uses flat files with random names, in
# subdirectories of `database/blob-storage` (relative to the current working
# directory). The default configuration also responds to environment variables.
# For instance, to store everything on S3:
#
# BLOB_STORAGE_PAGE_DATA_LOCATION="s3:overview-page-data"
# BLOB_STORAGE_FILE_CONTENTS_LOCATION="s3:overview-file-contents"
# BLOB_STORAGE_FILE_VIEW_LOCATION="s3:overview-file-view"
# BLOB_STORAGE_AWS_ACCESS_KEY_ID="....."
# BLOB_STORAGE_AWS_SECRET_KEY="....."
#
# These locations only apply when saving new blobs. Blobs that have been saved
# earlier will stay at their original locations even after you change this
# config. If you modify `file` or `s3` settings, you might render them
# inaccessible.
blobStorage {
  # When we're writing new blobs, we'll write to a specific "prefix". Think of
  # a "location prefix" as a directory. Here are the possible prefixes:
  #
  # * "pglo": store as a Postgres Large Object. Simplest; slow; doesn't scale
  #   well past one volume.
  #
  # * "file:dirname": store in subdirectory, `file.baseDirectory`/`dirname`.
  #   Simple; fast; doesn't scale well past one machine.
  #
  # * "s3:bucketname": store in S3 bucket `bucketname`. uses `s3.accessKeyId`
  #   and `s3.secretKey` as credentials. Cheap; scalable.
  #
  # If you set an incorrect value here, you'll get an error the first time you
  # write.
  #
  # If you are using S3, you may want to set the AWS_ACCESS_KEY_ID and
  # AWS_SECRET_KEY environment variables. Alternatively, run Overview from an
  # EC2 instance with an IAM role.
  preferredPrefixes: {
    # Overview saves each page of each uploaded file as a PDF.
    pageData: "file:page-data"
    pageData: ${?BLOB_STORAGE_PAGE_DATA_LOCATION}

    # Overview saves each original uploaded file as raw binary.
    fileContents: "file:file-contents"
    fileContents: ${?BLOB_STORAGE_FILE_CONTENTS_LOCATION}

    # Overview saves each original uploaded file as a PDF.
    fileView: "file:file-view"
    fileView: ${?BLOB_STORAGE_FILE_VIEW_LOCATION}
  }

  file: {
    # Where to save files when they use a "file:subdir" prefix
    #
    # This is the default for development environments.
    #
    # If you set an incorrect value here, you'll get an error the first time you
    # read or write.
    baseDirectory: "blob-storage"
    baseDirectory: ${?BLOB_STORAGE_FILE_BASE_DIRECTORY}
  }
}
